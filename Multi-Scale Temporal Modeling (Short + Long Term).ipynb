{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a95688c",
   "metadata": {},
   "source": [
    "Dynamic Spatial Modeling (Time-Varying Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c213ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_multiscale_inputs(x):\n",
    "    # x: [B, T, N, F] where T >= 48\n",
    "    short = x[:, -12:]                       # recent 1 hour\n",
    "    mid   = x[:, -24::2]                     # downsample (10 min)\n",
    "    long  = x[:, -48::4]                     # downsample (20 min)\n",
    "    return short, mid, long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88abbdcc",
   "metadata": {},
   "source": [
    "Multi-Scale Temporal Encoder\n",
    "\n",
    "Each scale gets its own temporal model (Mamba / Transformer / GRU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4670232c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class TemporalEncoder(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.mamba = Mamba(d_model=dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, N, F]\n",
    "        B, T, N, F = x.shape\n",
    "        x = x.view(B*N, T, F)\n",
    "        out = self.mamba(x)\n",
    "        return out[:, -1].view(B, N, F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c860e24",
   "metadata": {},
   "source": [
    "Temporal Scale Attention \n",
    "\n",
    "Let the model learn how much to trust each scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7879bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class TemporalScaleAttention(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, feats):\n",
    "        # feats: list of [B, N, F]\n",
    "        scores = [self.attn(f) for f in feats]\n",
    "        weights = torch.softmax(torch.stack(scores), dim=0)\n",
    "        fused = sum(w * f for w, f in zip(weights, feats))\n",
    "        return fused\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875e0d4",
   "metadata": {},
   "source": [
    "Final Temporal Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a2ec3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "short, mid, long = build_multiscale_inputs(x)\n",
    "\n",
    "f_s = self.temporal_short(short)\n",
    "f_m = self.temporal_mid(mid)\n",
    "f_l = self.temporal_long(long)\n",
    "\n",
    "temporal_out = self.scale_attention([f_s, f_m, f_l])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fdee6b",
   "metadata": {},
   "source": [
    "Now the model understands both sudden jams and daily patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620f688",
   "metadata": {},
   "source": [
    "# TemporalEncoder explanation:\n",
    "# - Input x has shape [B, T, N, F]\n",
    "#   B = batch size\n",
    "#   T = number of time steps\n",
    "#   N = number of nodes (e.g., sensors)\n",
    "#   F = feature dimension per node\n",
    "#\n",
    "# - `dim` passed to Mamba(d_model=dim) MUST equal F.\n",
    "#   The feature dimension is fixed at initialization and\n",
    "#   cannot change dynamically during forward().\n",
    "#\n",
    "# - Reshaping x to [B*N, T, F] treats each nodeâ€™s time series\n",
    "#   as an independent temporal sequence.\n",
    "#\n",
    "# - Mamba is a state-space model (NOT a Transformer):\n",
    "#   * No attention heads\n",
    "#   * No head splitting\n",
    "#   * No dimension permutation or reshuffling\n",
    "#\n",
    "# - Mamba preserves the input layout and returns output\n",
    "#   with the same shape [B*N, T, F].\n",
    "#\n",
    "# - `out[:, -1]` selects the final time step embedding\n",
    "#   for each (batch, node) sequence.\n",
    "#\n",
    "# - Reshaping back to [B, N, F] is safe because no\n",
    "#   permutation was performed between view() operations.\n",
    "#\n",
    "# - This module performs per-node temporal encoding only;\n",
    "#   spatial relationships must be modeled separately.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
